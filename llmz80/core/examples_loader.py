import logging
import random
import time
from pathlib import Path
from typing import Dict, List, Any, Optional, Tuple
import numpy as np

from ..utils.helpers import estimate_tokens

class ExamplesLoader:
    """Cargador de ejemplos de c√≥digo para diferentes plataformas."""
    
    def __init__(self, 
                 embedding_manager,
                 cache_manager, 
                 platform: str, 
                 example_dir_template: str,
                 max_example_size: int,
                 max_examples: int):
        """Inicializa el cargador de ejemplos.
        
        Args:
            embedding_manager: Administrador de embeddings
            cache_manager: Administrador de cach√©
            platform: Plataforma seleccionada
            example_dir_template: Plantilla para el directorio de ejemplos
            max_example_size: Tama√±o m√°ximo para ejemplos (antes de truncar)
            max_examples: N√∫mero m√°ximo de ejemplos a cargar
        """
        self.embedding_manager = embedding_manager
        self.cache_manager = cache_manager
        self.platform = platform
        self.example_dir_template = example_dir_template
        self.max_example_size = max_example_size
        self.max_examples = max_examples
        self.force_truncate = False
        self.use_embeddings = True
        self.embeddings_cache = {}
        
    def load_code_examples(self) -> List[Dict[str, str]]:
        """Carga ejemplos de c√≥digo para la plataforma seleccionada.
        
        Returns:
            Lista de diccionarios con {"path": ruta_relativa, "content": contenido}
        """
        examples_dir = Path(self.example_dir_template.format(platform=self.platform))
        logging.info(f"üìö Cargando ejemplos de c√≥digo para {self.platform.upper().replace('_', ' ')}...")
        
        examples = []
        
        # Intentar cargar el cach√© de embeddings
        self.embeddings_cache = self.cache_manager.load_cache()
        
        # Buscar recursivamente en todas las carpetas
        all_c_files = list(examples_dir.rglob('*.c'))
        if not all_c_files:
            logging.warning(f"‚ö†Ô∏è No se encontraron archivos .c en {examples_dir}")
            return examples
        
        # Calcular el n√∫mero aproximado de tokens
        estimated_max_tokens = estimate_tokens(self.max_example_size)
        logging.info(f"Tama√±o m√°ximo de ejemplo: {self.max_example_size} caracteres (~{estimated_max_tokens} tokens)")
        
        # Cargar contenido de archivos y generar embeddings si es necesario
        need_to_update_cache = False
        for file_path in all_c_files:
            rel_path = str(file_path.relative_to(examples_dir))
            
            # Verificar si necesitamos procesar este archivo
            # Lo hacemos si: no est√° en cach√© O si est√° en cach√© pero se fuerza truncado
            if rel_path not in self.embeddings_cache or self.force_truncate:
                # Cargar el archivo fresco
                try:
                    with open(file_path, 'r', encoding='utf-8') as f:
                        content = f.read()
                    
                    # Truncar ejemplos extremadamente grandes
                    original_size = len(content)
                    estimated_tokens = estimate_tokens(content)
                    
                    if original_size > self.max_example_size:
                        # Estrategia de truncado: mantener inicio y final
                        first_part_size = int(self.max_example_size * 0.7)  # 70% para el inicio
                        last_part_size = self.max_example_size - first_part_size  # 30% para el final
                        
                        first_part = content[:first_part_size]
                        last_part = content[-last_part_size:] if last_part_size > 0 else ""
                        
                        # Mensaje de truncaci√≥n
                        truncation_msg = f"\n/* ... CONTENIDO TRUNCADO ({original_size - self.max_example_size} caracteres) ... */\n"
                        
                        # Combinar las partes
                        content = first_part + truncation_msg + last_part
                        
                        logging.warning(f"‚ö†Ô∏è Ejemplo truncado: {rel_path} ({original_size} -> {len(content)} caracteres)")
                        logging.warning(f"   Tokens estimados: {estimated_tokens} -> {estimate_tokens(content)}")
                    
                    # Actualizar cach√© o a√±adir nueva entrada
                    self.embeddings_cache[rel_path] = (content, None)  # Embedding a None para regenerarlo despu√©s
                    examples.append({"path": rel_path, "content": content})
                    need_to_update_cache = True
                    
                    if self.force_truncate and rel_path in self.embeddings_cache:
                        logging.info(f"üîÑ Ejemplo recargado y truncado (forzado): {rel_path}")
                    
                except Exception as e:
                    logging.warning(f"Error al cargar ejemplo {file_path}: {e}")
            else:
                # El archivo ya est√° en la cach√©, usar su contenido y embedding
                content, _ = self.embeddings_cache[rel_path]
                examples.append({"path": rel_path, "content": content})
        
        # Generar embeddings para archivos nuevos o modificados
        if need_to_update_cache and self.use_embeddings:
            logging.info("Generando embeddings para nuevos archivos...")
            success_count = 0
            error_count = 0
            
            for rel_path, (content, embedding) in list(self.embeddings_cache.items()):
                if embedding is None:
                    # A√±adir una peque√±a pausa para evitar rate limits en la API
                    time.sleep(0.25)  # Pausa m√°s larga para evitar problemas de rate limiting
                    try:
                        # Para archivos extremadamente grandes, usar estrategia adaptativa
                        if len(content) > self.max_example_size * 1.5:
                            logging.warning(f"Archivo extremadamente grande ({len(content)} caracteres) en generaci√≥n de embeddings. Usando estrategia adaptativa.")
                            new_embedding = self.embedding_manager.get_embedding_for_large_file(content)
                        else:
                            # Para archivos de tama√±o normal, generar embedding directamente
                            new_embedding = self.embedding_manager.get_embedding(content)
                        
                        # VALIDACI√ìN AGREGADA: Verificar expl√≠citamente que el embedding es un array y no un escalar
                        if isinstance(new_embedding, (int, float)):
                            logging.error(f"‚ùå Error cr√≠tico: Embedding para {rel_path} es un escalar ({type(new_embedding)})")
                            # Reemplazar con un array vac√≠o para evitar el error 'int' has no len()
                            new_embedding = np.zeros((1536,), dtype=float)
                            logging.warning(f"Reemplazando embedding escalar con array vac√≠o para evitar errores")
                        
                        # Verificaci√≥n adicional para asegurar que es un array numpy
                        if not isinstance(new_embedding, np.ndarray):
                            logging.error(f"‚ùå Embedding para {rel_path} no es un array numpy ({type(new_embedding)})")
                            new_embedding = np.zeros((1536,), dtype=float)
                            
                        self.embeddings_cache[rel_path] = (content, new_embedding)
                        success_count += 1
                    except Exception as e:
                        logging.error(f"Error al generar embedding para {rel_path}: {e}")
                        # Asegurarse de que no hay valores escalares en la cach√©
                        self.embeddings_cache[rel_path] = (content, np.zeros((1536,), dtype=float))
                        error_count += 1
            
            logging.info(f"Embeddings generados: {success_count} exitosos, {error_count} con error")
            
            # Guardar el cach√© actualizado
            try:
                self.cache_manager.save_cache(self.embeddings_cache)
            except Exception as e:
                logging.error(f"Error al guardar cach√© de embeddings: {e}")
                logging.info("Intentando corregir cach√© antes de guardar...")
                # Intento de correcci√≥n: verificar y corregir cada entrada
                corrected_cache = {}
                for path, (content, emb) in self.embeddings_cache.items():
                    if isinstance(emb, (int, float)):
                        corrected_cache[path] = (content, np.zeros((1536,), dtype=float))
                    else:
                        corrected_cache[path] = (content, emb)
                self.embeddings_cache = corrected_cache
                # Intentar guardar nuevamente
                try:
                    self.cache_manager.save_cache(self.embeddings_cache)
                    logging.info("Cach√© corregido y guardado exitosamente.")
                except Exception as e2:
                    logging.error(f"No se pudo guardar el cach√© corregido: {e2}")
        
        logging.info(f"‚úÖ {len(examples)} ejemplos cargados.")
        return examples
        
    def load_code_examples_basic(self) -> List[Dict[str, str]]:
        """Carga ejemplos de c√≥digo de manera b√°sica sin usar embeddings.
        
        Returns:
            Lista de diccionarios con {"path": ruta_relativa, "content": contenido}
        """
        examples_dir = Path(self.example_dir_template.format(platform=self.platform))
        logging.info(f"üìö Cargando ejemplos de c√≥digo b√°sicos para {self.platform.upper().replace('_', ' ')}...")
        
        examples = []
        
        # Buscar recursivamente en todas las carpetas
        all_c_files = list(examples_dir.rglob('*.c'))
        if not all_c_files:
            logging.warning(f"‚ö†Ô∏è No se encontraron archivos .c en {examples_dir}")
            return examples
            
        # Si hay demasiados archivos, toma una muestra aleatoria para mayor diversidad
        if len(all_c_files) > self.max_examples * 3:
            random.shuffle(all_c_files)
            all_c_files = all_c_files[:self.max_examples * 3]
        
        # Cargar contenido de archivos
        for file_path in all_c_files:
            rel_path = str(file_path.relative_to(examples_dir))
            
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                # Truncar ejemplos extremadamente grandes
                original_size = len(content)
                
                if original_size > self.max_example_size:
                    # Estrategia de truncado
                    first_part_size = int(self.max_example_size * 0.7)
                    last_part_size = self.max_example_size - first_part_size
                    
                    first_part = content[:first_part_size]
                    last_part = content[-last_part_size:] if last_part_size > 0 else ""
                    
                    truncation_msg = f"\n/* ... CONTENIDO TRUNCADO ({original_size - self.max_example_size} caracteres) ... */\n"
                    content = first_part + truncation_msg + last_part
                    
                    logging.info(f"‚ö†Ô∏è Ejemplo truncado: {rel_path} ({original_size} -> {len(content)} caracteres)")
                
                examples.append({"path": rel_path, "content": content})
                
            except Exception as e:
                logging.warning(f"Error al cargar ejemplo {file_path}: {e}")
        
        logging.info(f"‚úÖ {len(examples)} ejemplos b√°sicos cargados.")
        
        # Ordenar por tama√±o para tomar una muestra variada
        examples.sort(key=lambda x: len(x["content"]))
        
        # Tomar ejemplos variados: algunos peque√±os, medianos y grandes
        result = []
        step = max(1, len(examples) // self.max_examples)
        for i in range(0, len(examples), step):
            if len(result) < self.max_examples:
                result.append(examples[i])
        
        return result
        
    def get_relevant_examples(self, user_request: str, max_examples: Optional[int] = None) -> List[Dict[str, str]]:
        """Obtiene los ejemplos m√°s relevantes para la solicitud del usuario.
        
        Args:
            user_request: Solicitud del usuario
            max_examples: N√∫mero m√°ximo de ejemplos a devolver (o None para usar el valor por defecto)
            
        Returns:
            Lista de ejemplos relevantes, cada uno como un diccionario {"path": ruta, "content": contenido}
        """
        if max_examples is None:
            max_examples = self.max_examples
        
        if not self.embeddings_cache:
            logging.warning("No hay cach√© de embeddings disponible para b√∫squeda sem√°ntica.")
            # Cargar todos los ejemplos como respaldo
            examples = self.load_code_examples()
            return examples[:max_examples]
        
        logging.info(f"üîç Buscando {max_examples} ejemplos relevantes para la solicitud...")
        
        # Obtener embedding para la solicitud del usuario
        query_embedding = self.embedding_manager.get_embedding(user_request)
        
        # Verificar que el embedding sea v√°lido
        if not isinstance(query_embedding, np.ndarray) or query_embedding.size == 0 or np.all(query_embedding == 0):
            logging.warning("‚ùå No se pudo generar un embedding v√°lido para la consulta. Usando ejemplos aleatorios.")
            # Si no tenemos un embedding v√°lido para la consulta, devolver algunos ejemplos de forma aleatoria
            all_examples = []
            for rel_path, (content, _) in self.embeddings_cache.items():
                all_examples.append({"path": rel_path, "content": content})
            
            # Limitar a la cantidad solicitada
            random.shuffle(all_examples)
            return all_examples[:max_examples]
        
        # Calcular similitud con todos los ejemplos
        similarities = []
        valid_embeddings_count = 0
        invalid_embeddings_count = 0
        
        for rel_path, (content, embedding) in self.embeddings_cache.items():
            # VERIFICACI√ìN CR√çTICA: Detecci√≥n de embeddings escalares (int/float)
            # Esta es la fuente potencial del error "object of type 'int' has no len()"
            if isinstance(embedding, (int, float)):
                logging.error(f"‚ö†Ô∏è ERROR CR√çTICO: Se detect√≥ un embedding escalar ({type(embedding)}) para {rel_path}")
                logging.error(f"üìç CAUSA DEL ERROR 'object of type int has no len()' en llmz80/core/examples_loader.py:get_relevant_examples")
                # Crear un embedding vac√≠o para evitar que falle el algoritmo
                embedding = np.zeros((1536,), dtype=float)
                # Actualizar el cach√© con el embedding corregido
                self.embeddings_cache[rel_path] = (content, embedding)
                invalid_embeddings_count += 1
            
            # Verificar que el embedding sea v√°lido
            if (embedding is not None and 
                isinstance(embedding, np.ndarray) and 
                embedding.size > 0 and 
                not np.all(embedding == 0)):
                try:
                    # PROTECCI√ìN ADICIONAL: Verificar expl√≠citamente ambos argumentos
                    if not isinstance(query_embedding, np.ndarray):
                        logging.error(f"‚ö†Ô∏è Error en cosine_similarity: query_embedding no es numpy array: {type(query_embedding)}")
                        continue
                    if not isinstance(embedding, np.ndarray):
                        logging.error(f"‚ö†Ô∏è Error en cosine_similarity: embedding para {rel_path} no es numpy array: {type(embedding)}")
                        continue
                        
                    # Intentar calcular similitud con manejo de errores expl√≠cito
                    try:
                        similarity = self.embedding_manager.cosine_similarity(query_embedding, embedding)
                        similarities.append((rel_path, content, similarity))
                        valid_embeddings_count += 1
                    except TypeError as e:
                        if "object of type 'int' has no len()" in str(e):
                            logging.error(f"‚ö†Ô∏è ERROR 'int' has no len() al calcular similitud para {rel_path}")
                            logging.error(f"üìç Tipos: query_embedding={type(query_embedding)}, embedding={type(embedding)}")
                            invalid_embeddings_count += 1
                        else:
                            raise
                except Exception as e:
                    logging.warning(f"Error al calcular similitud para {rel_path}: {e}")
                    invalid_embeddings_count += 1
            else:
                invalid_embeddings_count += 1
                # No lo incluimos para c√°lculo de similitud
        
        # Si se detectaron problemas con los embeddings, intentar reparar el cach√©
        if invalid_embeddings_count > 0:
            logging.warning(f"Se ignoraron {invalid_embeddings_count} embeddings inv√°lidos o nulos.")
            # Intentar guardar el cach√© corregido
            try:
                self.cache_manager.save_cache(self.embeddings_cache)
                logging.info("‚úÖ Cach√© corregido guardado autom√°ticamente.")
            except Exception as e:
                logging.error(f"Error al guardar cach√© corregido: {e}")
        
        if not similarities:
            logging.warning("‚ùå No se encontraron embeddings v√°lidos para comparar. Usando ejemplos aleatorios.")
            # Si no hay embeddings v√°lidos, devolver algunos ejemplos de forma aleatoria
            all_examples = []
            for rel_path, (content, _) in self.embeddings_cache.items():
                all_examples.append({"path": rel_path, "content": content})
            
            # Limitar a la cantidad solicitada
            random.shuffle(all_examples)
            return all_examples[:max_examples]
        
        # Ordenar por similitud descendente
        similarities.sort(key=lambda x: x[2], reverse=True)
        
        # Tomar los N ejemplos m√°s relevantes
        relevant_examples = []
        for rel_path, content, similarity in similarities[:max_examples]:
            logging.debug(f"Ejemplo relevante: {rel_path} (similitud: {similarity:.4f})")
            relevant_examples.append({"path": rel_path, "content": content})
        
        logging.info(f"‚úÖ Se encontraron {len(relevant_examples)} ejemplos relevantes (de {valid_embeddings_count} v√°lidos).")
        return relevant_examples 