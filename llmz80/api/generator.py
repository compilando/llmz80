import logging
import os
from pathlib import Path
from typing import Dict, List, Any, Optional
from openai import OpenAI
import numpy as np

# Obtener instancia del logger para este m√≥dulo
logger = logging.getLogger(__name__)

from ..core.embeddings import EmbeddingsManager
from ..core.cache_manager import EmbeddingsCacheManager
from ..core.examples_loader import ExamplesLoader
from ..utils.helpers import clean_api_response, get_output_paths
from vector_db import get_qdrant_client, search_similar

class LLMZ80Generator:
    """Generador de c√≥digo Z80 utilizando LLMs."""
    
    def __init__(self, platform: str, global_vars: Dict[str, Any], api_key: str):
        """Inicializa el generador de c√≥digo Z80.
        
        Args:
            platform: Plataforma objetivo (spectrum, amstrad_cpc, etc.)
            global_vars: Variables globales de configuraci√≥n
            api_key: Clave de API para OpenAI
        """
        self.platform = platform.lower()
        self.global_vars = global_vars
        
        # Inicializaci√≥n del cliente de OpenAI
        self.api_key = api_key
        self.client = OpenAI(api_key=self.api_key)
        
        # Opciones de configuraci√≥n
        self.model = global_vars['model']
        self.temperature = global_vars['temperature']
        self.max_tokens = global_vars['max_tokens']
        self.max_examples = global_vars['max_examples']
        self.system_prompt_file = global_vars['system_prompt_file']
        self.base_output_dir = global_vars['base_output_dir']
        self.slug_max_length = global_vars['slug_max_length']
        
        # Opciones para la b√∫squeda sem√°ntica
        self.use_embeddings = True
        self.force_truncate = False
        
        # Inicializar manejadores
        self.embedding_manager = EmbeddingsManager(
            self.client,
            self.platform,
            global_vars
        )
        
        self.cache_manager = EmbeddingsCacheManager(
            self.platform,
            global_vars['embeddings_cache_dir']
        )
        
        self.examples_loader = ExamplesLoader(
            self.embedding_manager,
            self.cache_manager,
            self.platform,
            global_vars['example_dir_template'],
            global_vars['max_example_size'],
            self.max_examples
        )
        
        logging.info(f"üöÄ Inicializando Generador de C√≥digo LLMZ80 para {self.platform.upper().replace('_', ' ')}")
        logging.info(f"‚öôÔ∏è Usando Modelo: {self.model}, Temp: {self.temperature}, Max Tokens: {self.max_tokens}, Max Ejemplos: {self.max_examples}")
        logging.info("‚úÖ Generador inicializado correctamente.")
        
    def set_force_truncate(self, value: bool) -> None:
        """Establece la opci√≥n para forzar el truncado de ejemplos.
        
        Args:
            value: True para forzar truncado, False en caso contrario
        """
        self.force_truncate = value
        self.examples_loader.force_truncate = value
        if value:
            logging.info("Modo de truncado forzado activado.")
        else:
            logging.info("Modo de truncado forzado desactivado.")
            
    def set_use_embeddings(self, value: bool) -> None:
        """Establece la opci√≥n para usar embeddings en la b√∫squeda sem√°ntica.
        
        Args:
            value: True para usar embeddings, False para usar ejemplos b√°sicos
        """
        self.use_embeddings = value
        self.examples_loader.use_embeddings = value
        if value:
            logging.info("Uso de embeddings activado para b√∫squeda sem√°ntica.")
        else:
            logging.info("Uso de embeddings desactivado. Se utilizar√°n ejemplos b√°sicos.")
            
    def rebuild_embeddings_cache(self) -> None:
        """Elimina y reconstruye completamente el cach√© de embeddings."""
        # Delegar al administrador de cach√© y ejemplos
        self.cache_manager.clear_cache()
        
        # Cargar todos los ejemplos (esto regenerar√° los embeddings)
        self.examples_loader.load_code_examples()
        
        logging.info("‚úÖ Reconstrucci√≥n de cach√© de embeddings completada.")
        
    def test_file_embedding(self, file_path: str) -> None:
        """Prueba la generaci√≥n de embeddings para un archivo espec√≠fico.
        
        Args:
            file_path: Ruta al archivo a probar
        """
        try:
            # Verificar que el archivo existe
            if not os.path.exists(file_path):
                logging.error(f"‚ö†Ô∏è El archivo {file_path} no existe")
                return
                
            logging.info(f"üß™ Probando generaci√≥n de embedding para archivo: {file_path}")
            
            # Cargar contenido del archivo
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
                
            # Mostrar info del archivo
            file_size = len(content)
            from ..utils.helpers import estimate_tokens
            estimated_tokens = estimate_tokens(content)
            logging.info(f"üìÑ Tama√±o del archivo: {file_size} caracteres (~{estimated_tokens} tokens estimados)")
            
            # Primero intentar con el m√©todo est√°ndar
            logging.info("üîÑ Intentando m√©todo est√°ndar de embedding...")
            try:
                import time
                start_time = time.time()
                embedding = self.embedding_manager.get_embedding(content)
                elapsed = time.time() - start_time
                
                if isinstance(embedding, np.ndarray) and embedding.size > 0 and not np.all(embedding == 0):
                    logging.info(f"‚úÖ Embedding generado correctamente con m√©todo est√°ndar en {elapsed:.2f} segundos")
                    logging.info(f"   Dimensiones: {embedding.shape}, Norma: {norm(embedding):.4f}")
                else:
                    logging.warning(f"‚ö†Ô∏è El m√©todo est√°ndar no gener√≥ un embedding v√°lido")
            except Exception as e:
                logging.error(f"‚ùå Error al generar embedding con m√©todo est√°ndar: {e}")
                
            # Luego intentar con el m√©todo para archivos grandes
            logging.info("üîÑ Intentando m√©todo para archivos grandes...")
            try:
                start_time = time.time()
                large_embedding = self.embedding_manager.get_embedding_for_large_file(content)
                elapsed = time.time() - start_time
                
                if isinstance(large_embedding, np.ndarray) and large_embedding.size > 0 and not np.all(large_embedding == 0):
                    logging.info(f"‚úÖ Embedding generado correctamente con m√©todo para archivos grandes en {elapsed:.2f} segundos")
                    from numpy.linalg import norm
                    logging.info(f"   Dimensiones: {large_embedding.shape}, Norma: {norm(large_embedding):.4f}")
                else:
                    logging.warning(f"‚ö†Ô∏è El m√©todo para archivos grandes no gener√≥ un embedding v√°lido")
            except Exception as e:
                logging.error(f"‚ùå Error al generar embedding con m√©todo para archivos grandes: {e}")
                
            logging.info("üèÅ Prueba de generaci√≥n de embedding completada")
            
        except Exception as e:
            logging.error(f"‚ùå Error al probar el archivo {file_path}: {e}")
    
    def _load_platform_instructions(self) -> str:
        """Carga instrucciones espec√≠ficas de la plataforma desde el archivo de prompt del sistema.
        
        Returns:
            Contenido del archivo de prompt
        """
        logging.info(f"üìö Cargando instrucciones de plataforma desde {self.system_prompt_file}...")
        content = ""
        try:
            if os.path.exists(self.system_prompt_file):
                with open(self.system_prompt_file, 'r', encoding='utf-8') as f:
                    content = f.read()
                logging.info(f"‚úÖ Instrucciones de plataforma cargadas ({len(content)} caracteres).")
            else:
                logging.warning(f"‚ö†Ô∏è Archivo de instrucciones de plataforma no encontrado: {self.system_prompt_file}")
        except Exception as e:
            logging.error(f"‚ùå Error al leer instrucciones de plataforma desde {self.system_prompt_file}: {e}")
        return content
        
    def _load_error_documentation(self) -> str:
        """Carga documentaci√≥n de errores (*.md) recursivamente desde el directorio de ejemplos.
        
        Returns:
            Contenido combinado de la documentaci√≥n
        """
        examples_dir = Path(self.global_vars['example_dir_template'].format(platform=self.platform))
        error_doc_pattern = self.global_vars['error_doc_glob_pattern']
        logging.info(f"üìö Cargando documentaci√≥n de errores desde {examples_dir}...")
        docs_content = ""

        if not examples_dir.is_dir():
            logging.warning(f"‚ö†Ô∏è Directorio de ejemplos no encontrado para documentaci√≥n de errores: {examples_dir}")
            return docs_content

        md_files = list(examples_dir.rglob(error_doc_pattern))

        if not md_files:
            logging.info("‚ÑπÔ∏è No se encontraron archivos de documentaci√≥n (.md).")
            return docs_content

        logging.info(f"Se encontraron {len(md_files)} archivos de documentaci√≥n.")
        for md_file in md_files:
            try:
                with open(md_file, 'r', encoding='utf-8') as f:
                    file_content = f.read()
                    relative_path = md_file.relative_to(examples_dir)
                    docs_content += f"\n\n--- DOCUMENTATION: {relative_path} ---\n\n"
                    docs_content += file_content
                    logging.debug(f"  Documentaci√≥n cargada: {relative_path}")
            except Exception as e:
                logging.error(f"‚ùå Error al cargar documentaci√≥n {md_file}: {e}")

        logging.info(f"‚úÖ Documentaci√≥n de errores cargada ({len(docs_content)} caracteres).")
        return docs_content
        
    def _build_system_prompt(self, relevant_examples: List[Dict[str, str]] = None) -> str:
        """Construye el prompt completo del sistema incorporando instrucciones base, ejemplos y documentaci√≥n.
        
        Args:
            relevant_examples: Lista de ejemplos relevantes a incluir
            
        Returns:
            Prompt completo del sistema
        """
        logging.debug("Construyendo prompt del sistema...")

        # 1. Instrucciones Base
        if self.platform == 'spectrum':
            base_prompt = """You are an expert Z88DK C code generator for ZX Spectrum 48K.
CRITICAL: Output ONLY the raw C source code. No introductory text, no explanations, no markdown fences (```), just the code itself.
Ensure the code is complete, directly compilable with 'zcc +zx', and functional on a ZX Spectrum 48K.
Adhere strictly to Z88DK's C dialect and library functions suitable for the Spectrum.
Prioritize clarity, efficiency for the Z80, and correct hardware interaction (screen, keyboard, sound if applicable).
"""
        elif self.platform == 'amstrad_cpc':
            base_prompt = """You are an expert CPCtelera C code generator for Amstrad CPC 464/6128.
CRITICAL: Output ONLY the raw C source code. No introductory text, no explanations, no markdown fences (```), just the code itself.
Ensure the code is complete, directly compilable with the CPCtelera toolchain, and functional on an Amstrad CPC.
Adhere strictly to the CPCtelera API and best practices. Do NOT use generic Z88DK functions unless they are part of the official CPCtelera API.
Prioritize clarity, efficiency for the Z80, static memory management, and correct hardware interaction using CPCtelera functions (graphics modes, keyboard, sound, etc.).
"""
        else:
            # Fallback - Consider raising an error for unsupported platforms
            logging.error(f"‚ùå Plataforma no soportada para prompt del sistema: {self.platform}")
            raise ValueError(f"Plataforma no soportada: {self.platform}")

        # 2. Instrucciones Espec√≠ficas de la Plataforma desde Archivo
        platform_instructions = self._load_platform_instructions()

        # 3. Ejemplos de C√≥digo
        examples_prompt_part = "\n--- CODE EXAMPLES ---\n"
        examples_prompt_part += "Use the following examples as a reference for style, structure, and API usage:\n"
        
        # Usar los ejemplos relevantes proporcionados o cargar todos si no se proporcionan
        if relevant_examples is None:
            # Cargar ejemplos b√°sicos si no se usan embeddings
            if self.use_embeddings:
                examples_to_use = self.examples_loader.load_code_examples()[:self.max_examples]
            else:
                examples_to_use = self.examples_loader.load_code_examples_basic()[:self.max_examples]
        else:
            examples_to_use = relevant_examples

        # A√±adir ejemplos al prompt
        for i, example in enumerate(examples_to_use):
            # Recuperar path, contenido (source_code) y la descripci√≥n
            path = example.get('path', 'unknown_path')
            content = example.get('content', '#error: content not found') # 'content' ahora tiene el source_code
            description = example.get('description', '') # Obtener la descripci√≥n del payload
            score = example.get('score', 0.0) # Opcional: mostrar score

            # A√±adir score al encabezado del ejemplo
            examples_prompt_part += f"\n--- Example {i+1} (Retrieved from: '{path}' - Relevance: {score:.4f}) ---"
            # A√±adir la descripci√≥n si existe
            if description:
                examples_prompt_part += f"\nDescription: {description}\n"
            # A√±adir el c√≥digo fuente
            examples_prompt_part += f"\nCode:\n```c\n{content}\n```\n"
        
        # 4. Documentaci√≥n de Errores
        error_docs = self._load_error_documentation()

        # 5. Combinar todas las partes
        full_system_prompt = base_prompt
        if platform_instructions:
             full_system_prompt += "\n--- PLATFORM INSTRUCTIONS ---\n" + platform_instructions
        if examples_to_use:
            full_system_prompt += examples_prompt_part
        if error_docs:
            # Append error docs (already contains header)
            full_system_prompt += error_docs
        # Final reminder
        full_system_prompt += "\n--- FINAL INSTRUCTIONS ---\nRemember: ONLY output the raw C code. No extra text or markdown."

        logging.debug(f"Prompt del sistema construido ({len(full_system_prompt)} caracteres).")
        return full_system_prompt
        
    def _build_user_prompt(self, user_request: str) -> str:
        """Builds the user prompt.
        
        Args:
            user_request: The user's request
            
        Returns:
            Formatted user prompt string
        """
        platform_name = self.platform.replace('_', ' ')
        # Keep it direct and clear
        return f"""Generate {platform_name} C code according to the system instructions that fulfills the following request: {user_request}

Please provide specific details about desired behaviors, controls, graphics mode (if applicable), and any other relevant technical requirements."""
        
    def generate_c_code(self, user_request: str) -> str:
        """Genera c√≥digo C utilizando la API de OpenAI basado en la solicitud del usuario y el contexto.
        
        Args:
            user_request: Solicitud del usuario
            
        Returns:
            C√≥digo C generado
        """
        logging.info(f"ü§ñ Generando c√≥digo para: '{user_request[:100]}...'")

        relevant_examples_content = []
        
        if self.use_embeddings:
            logging.info("üîç Buscando ejemplos relevantes en la base de datos vectorial...")
            try:
                # 1. Obtener cliente Qdrant
                qdrant_client = get_qdrant_client()
                if not qdrant_client:
                    raise ConnectionError("No se pudo conectar a Qdrant.")

                # 2. Generar embedding para el prompt del usuario
                prompt_embedding = self.embedding_manager.get_embedding(user_request)
                if prompt_embedding is None or not isinstance(prompt_embedding, np.ndarray) or prompt_embedding.size == 0:
                     raise ValueError("No se pudo generar un embedding v√°lido para el prompt.")
                # --- DEBUG: Log prompt embedding --- 
                logger.debug(f"Embedding del Prompt (primeros 5 dims): {prompt_embedding[:5]}")
                logger.debug(f"Norma del Embedding del Prompt: {np.linalg.norm(prompt_embedding):.4f}")
                # ----------------------------------

                # 3. Buscar en Qdrant
                search_results = search_similar(
                    client=qdrant_client,
                    platform=self.platform,
                    vector=prompt_embedding.tolist(), # Qdrant espera una lista
                    limit=self.max_examples
                )
                # --- DEBUG: Log search results --- 
                logger.debug(f"Resultados crudos de Qdrant ({len(search_results)} encontrados):")
                for i, (payload, score) in enumerate(search_results):
                    logger.debug(f"  {i+1}. Score: {score:.4f}, Path: {payload.get('file_path', 'N/A')}, Desc: '{payload.get('description', 'N/A')[:50]}...'")
                # --------------------------------

                # 4. Cargar contenido de los archivos encontrados
                if search_results:
                    logging.info(f"‚úÖ Se encontraron {len(search_results)} ejemplos relevantes en Qdrant.")
                    examples_dir = Path(self.global_vars['example_dir_template'].format(platform=self.platform))
                    loaded_paths = set() # Para evitar cargar el mismo archivo m√∫ltiples veces si tiene varios chunks
                    
                    for payload, score in search_results:
                        relative_path_str = payload.get("file_path")
                        if relative_path_str and relative_path_str not in loaded_paths:
                            file_path = examples_dir / relative_path_str
                            if file_path.exists():
                                try:
                                    with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                                        content = f.read()
                                        # Truncar si es necesario (usando la l√≥gica existente si aplica)
                                        if len(content) > self.global_vars['max_example_size']:
                                            content = content[:self.global_vars['max_example_size']]
                                            logging.debug(f"Truncando ejemplo de Qdrant: {relative_path_str}")
                                            
                                        relevant_examples_content.append({
                                            'path': relative_path_str,
                                            'content': content,
                                            'score': score # Guardar score por si es √∫til
                                        })
                                        loaded_paths.add(relative_path_str)
                                except Exception as read_exc:
                                    logging.warning(f"‚ö†Ô∏è Error leyendo archivo de ejemplo {file_path} desde Qdrant: {read_exc}")
                            else:
                                logging.warning(f"‚ö†Ô∏è Archivo de ejemplo referenciado en Qdrant no encontrado: {file_path}")
                else:
                    logging.warning("‚ö†Ô∏è No se encontraron ejemplos relevantes en Qdrant.")

            except Exception as e:
                logging.error(f"‚ùå Error durante la b√∫squeda en Qdrant: {e}")
                logging.warning("‚¨áÔ∏è Recurriendo a la carga b√°sica de ejemplos (sin b√∫squeda sem√°ntica).")
                # Fallback: Cargar ejemplos b√°sicos si falla Qdrant
                all_examples = self.examples_loader.load_code_examples_basic()
                relevant_examples_content = all_examples[:self.max_examples]
        
        # Si no se usan embeddings o si Qdrant fall√≥ y no se cargaron ejemplos en el fallback
        if not self.use_embeddings or not relevant_examples_content:
            if not relevant_examples_content: # Asegurar que cargamos algo si Qdrant fall√≥
                 logging.info(f"‚öôÔ∏è Usando selecci√≥n b√°sica de ejemplos (sin b√∫squeda sem√°ntica).")
                 all_examples = self.examples_loader.load_code_examples_basic()
                 relevant_examples_content = all_examples[:self.max_examples]
        
        # Construir el prompt del sistema con los ejemplos seleccionados
        system_prompt = self._build_system_prompt(relevant_examples_content)
        user_prompt = self._build_user_prompt(user_request)

        # Log prompts for debugging (optional, consider security/privacy)
        # logging.debug(f"System Prompt:\n{system_prompt}")
        # logging.debug(f"User Prompt:\n{user_prompt}")

        try:
            logging.info(f"üìû Llamando a la API de OpenAI (Modelo: {self.model})...")
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                temperature=self.temperature,
                max_tokens=self.max_tokens
            )

            raw_code = response.choices[0].message.content
            logging.info("‚úÖ Llamada a la API exitosa.")
            #logging.debug(f"Raw API response:\n{raw_code}") # Log raw response if needed

            cleaned_code = clean_api_response(raw_code)
            logging.info("‚ú® Generaci√≥n de c√≥digo completada.")
            return cleaned_code

        except Exception as e:
            logging.error(f"‚ùå Error durante llamada a la API de OpenAI o procesamiento: {e}")
            # Consider more specific error handling for API errors (e.g., rate limits, auth)
            raise # Re-raise to indicate failure
            
    def save_generated_files(self, code: str, prompt: str) -> Dict[str, Path]:
        """Guarda el c√≥digo C generado, el prompt original y la informaci√≥n de la plataforma.
        
        Args:
            code: C√≥digo C generado
            prompt: Prompt original del usuario
            
        Returns:
            Diccionario con las rutas de los archivos generados
        """
        logging.info("üíæ Guardando archivos generados...")
        
        try:
            # Obtener las rutas de salida
            paths = get_output_paths(
                prompt, 
                self.platform, 
                self.base_output_dir, 
                self.slug_max_length
            )

            # Asegurar que los directorios base y obj existan
            paths['base'].mkdir(parents=True, exist_ok=True)
            paths['obj_dir'].mkdir(exist_ok=True) # obj_dir debe estar bajo base

            # Guardar c√≥digo C
            with open(paths['c_file'], 'w', encoding='utf-8') as f:
                f.write(code)
            logging.info(f"  üìÑ C√≥digo C guardado en: {paths['c_file']}")

            # Guardar prompt original
            with open(paths['prompt_file'], 'w', encoding='utf-8') as f:
                f.write(prompt)
            logging.info(f"  üìù Prompt guardado en: {paths['prompt_file']}")

            # Guardar informaci√≥n de la plataforma
            with open(paths['platform_file'], 'w', encoding='utf-8') as f:
                f.write(self.platform)
            logging.info(f"  ‚ÑπÔ∏è Informaci√≥n de plataforma guardada en: {paths['platform_file']}")

            logging.info("‚úÖ Todos los archivos guardados correctamente!")
            logging.info(f"  üìÅ Directorio de Salida: {paths['base'].resolve()}")
            logging.info(f"  üõ†Ô∏è Directorio de Build/Objetos: {paths['obj_dir'].resolve()}")

            return paths
        except Exception as e:
            logging.error(f"‚ùå Error al guardar archivos: {e}")
            raise 